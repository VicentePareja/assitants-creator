A. ajustar implementación actual (Done.)

B. Ver qué onda con el evals de OPENAI si tiene API.(Done)

C.
Testeo "ordenado" (estático):

1. Crear batería de test (Tentativo: usar ejemplos basales). Worst 4 y porcentaje de correctitud (Done)
2. asistente evaluador (semantico ¿más contexto?) modelo mejor. Con instructions para contexto. (Done, se toman las respuestas humanas por correctas)
3. Se compara todo en ambiente controlado y se guarda una calificaciones para cada asistente. 

4. recovery ante caída de internet.

----------------> 05: without examples, 06: Base, 07: Fine tunned

Testeo "en la cancha" (dinámico):

1. Extraer todas las veces que aparece una pregunta importante en las conversaciones reales.
Nota: Cuidado con los tamaños de los archivos.

2. Evaluar con un modelo avanzado la calidad de las respuestas. Y guardar esos datos.

Data analitics:

1. informe testeo ordenado
2. informe en la cancha


D. Refactorar main.py

E. Agregar cutomization to assitant creation: Temperature.

F. jsonl to excel?


--------------------------------


Reu 30/12

-Reporte.
-Automatizar evals.
-W&B